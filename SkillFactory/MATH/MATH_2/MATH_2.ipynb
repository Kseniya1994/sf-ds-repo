{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [3, 5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.4\n",
    "A = np.array([[1,1],[1,2]])\n",
    "A.T@A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.7\n",
    "A = np.array([[2,10,-2], [3,2,-2], [8,14,-6]]).T\n",
    "np.linalg.matrix_rank(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Линейная регрессия по методу наименьших квадратов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка библиотек\n",
    "import numpy as np # для работы с массивами\n",
    "import pandas as pd # для работы с DataFrame \n",
    "from sklearn import datasets # для импорта данных\n",
    "import seaborn as sns # для визуализации статистических данных\n",
    "import matplotlib.pyplot as plt # для построения графиков\n",
    "\n",
    "# загружаем датасет\n",
    "boston = datasets.load_boston()\n",
    "boston_data = pd.DataFrame(\n",
    "    data=boston.data, #данные\n",
    "    columns=boston.feature_names #наименования столбцов\n",
    ")\n",
    "boston_data['PRICE'] = boston.target\n",
    "boston_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000e+00 6.3200e-03 6.5750e+00]\n",
      " [1.0000e+00 2.7310e-02 6.4210e+00]\n",
      " [1.0000e+00 2.7290e-02 7.1850e+00]\n",
      " ...\n",
      " [1.0000e+00 6.0760e-02 6.9760e+00]\n",
      " [1.0000e+00 1.0959e-01 6.7940e+00]\n",
      " [1.0000e+00 4.7410e-02 6.0300e+00]]\n"
     ]
    }
   ],
   "source": [
    "# составляем матрицу А и вектор целевой переменной\n",
    "CRIM = boston_data['CRIM']\n",
    "RM = boston_data['RM']\n",
    "A = np.column_stack((np.ones(506), CRIM, RM))\n",
    "y = boston_data[['PRICE']]\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 3)\n"
     ]
    }
   ],
   "source": [
    "# проверим размерность\n",
    "print(A.shape)\n",
    "## (506, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-29.24471945]\n",
      " [ -0.26491325]\n",
      " [  8.39106825]]\n"
     ]
    }
   ],
   "source": [
    "# вычислим OLS-оценку для коэффициентов\n",
    "w_hat = np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37.85733519]\n"
     ]
    }
   ],
   "source": [
    "# добавились новые данные:\n",
    "CRIM_new = 0.1\n",
    "RM_new = 8\n",
    "# делаем прогноз типичной стоимости дома\n",
    "PRICE_new = w_hat.iloc[0]+w_hat.iloc[1]*CRIM_new+w_hat.iloc[2]*RM_new\n",
    "print(PRICE_new.values)\n",
    "## [37.85733519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [[37.85733519]]\n"
     ]
    }
   ],
   "source": [
    "# → Согласитесь, такая запись вычисления оценки стоимости слишком длинная и неудобная, особенно если факторов не два, как у нас, а 200. \n",
    "# Более короткий способ сделать прогноз — вычислить скалярное произведение вектора признаков и коэффициентов регрессии.\n",
    "\n",
    "# короткий способ сделать прогноз\n",
    "new=np.array([[1,CRIM_new,RM_new]])\n",
    "print('prediction:', (new@w_hat).values)\n",
    "## prediction: [[37.85733519]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_hat: [[-29.24471945  -0.26491325   8.39106825]]\n",
      "prediction: [[37.85733519]]\n"
     ]
    }
   ],
   "source": [
    "#Мы уже знаем, что алгоритм построения модели линейной регрессии по МНК реализован в классе LinearRegression, \n",
    "# находящемся в модуле sklearn.linear_model. \n",
    "# Для вычисления коэффициентов (обучения модели) нам достаточно передать в метод fit() нашу матрицу с наблюдениями и вектор целевой переменной,\n",
    "# а для построения прогноза — вызвать метод predict():\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# создаём модель линейной регрессии\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "# вычисляем коэффициенты регрессии\n",
    "model.fit(A, y)\n",
    "print('w_hat:', model.coef_)\n",
    "new_prediction = model.predict(new)\n",
    "print('prediction:', new_prediction)\n",
    "## w_hat: [[-29.24471945  -0.26491325   8.39106825]]\n",
    "## prediction: [[37.85733519]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [[21.04870738]]\n"
     ]
    }
   ],
   "source": [
    "# 3.5\n",
    "# Сделайте прогноз типичной стоимости (в тыс. долларов) дома в городе с уровнем преступности  и средним количеством комнат в доме \n",
    "CRIM_new = 0.2\n",
    "RM_new = 6 \n",
    "# В качестве модели используйте линейную регрессию, оценка вектора коэффициентов которой равна: \n",
    "# w_hat = [[-29.24471945  -0.26491325   8.39106825]]\n",
    "\n",
    "new=np.array([[1,CRIM_new,RM_new]])\n",
    "print('prediction:', (new@w_hat).values)\n",
    "#Ответ округлите до целого числа.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОСОБЕННОСТИ КЛАССА LINEAR REGRESSION БИБЛИОТЕКИ SKLEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, что «скажет» Python, если мы попробуем построить модель линейной регрессии на вырожденной матрице наблюдений, используя классическую формулу линейной регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/kseniamasnikova/IDE/SkillFactory/MATH/MATH_2/MATH_2.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kseniamasnikova/IDE/SkillFactory/MATH/MATH_2/MATH_2.ipynb#ch0000012?line=6'>7</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m1\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kseniamasnikova/IDE/SkillFactory/MATH/MATH_2/MATH_2.ipynb#ch0000012?line=7'>8</a>\u001b[0m \u001b[39m# вычислим OLS-оценку для коэффициентов\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kseniamasnikova/IDE/SkillFactory/MATH/MATH_2/MATH_2.ipynb#ch0000012?line=8'>9</a>\u001b[0m w_hat\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(A\u001b[39m.\u001b[39;49mT\u001b[39m@A\u001b[39;49m)\u001b[39m@A\u001b[39m\u001b[39m.\u001b[39mT\u001b[39m@y\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kseniamasnikova/IDE/SkillFactory/MATH/MATH_2/MATH_2.ipynb#ch0000012?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(w_hat)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py:545\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py?line=542'>543</a>\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py?line=543'>544</a>\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py?line=544'>545</a>\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py?line=545'>546</a>\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py:88\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py?line=86'>87</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m---> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py?line=87'>88</a>\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# создадим вырожденную матрицу А\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1], \n",
    "    [2, 1, 1, 2], \n",
    "    [-2, -1, -1, -2]]\n",
    ").T\n",
    "y = np.array([1, 2, 5, 1])\n",
    "# вычислим OLS-оценку для коэффициентов\n",
    "w_hat=np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat) \n",
    "## LinAlgError: Singular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить модель линейной регрессии LinearRegression из модуля sklearn, используя нашу вырожденную матрицу :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_hat: [ 6.   -1.25  1.25]\n"
     ]
    }
   ],
   "source": [
    "# создаём модель линейной регрессии\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "# вычисляем коэффициенты регрессии\n",
    "model.fit(A, y)\n",
    "print('w_hat:', model.coef_)\n",
    "## w_hat: [ 6.   -1.25  1.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.  , -1.25,  1.25]),\n",
       " array([], dtype=float64),\n",
       " 2,\n",
       " array([4.86435029e+00, 5.81460412e-01, 3.42443768e-17]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Примечание. На самом деле сингулярное разложение зашито в функцию np.linalg.lstsq(), которая позволяет в одну строку построить модель линейной регрессии по МНК:\n",
    "\n",
    "# классическая OLS-регрессия в numpy с возможностью получения решения даже для вырожденных матриц\n",
    "np.linalg.lstsq(A, y, rcond=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Стандартизация векторов и матрица корреляций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.069170</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>3.613524</td>\n",
       "      <td>6.284634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.253994</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>8.601545</td>\n",
       "      <td>0.702617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>3.561000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>5.885500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>0.256510</td>\n",
       "      <td>6.208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>3.677083</td>\n",
       "      <td>6.623500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>88.976200</td>\n",
       "      <td>8.780000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CHAS       LSTAT        CRIM          RM\n",
       "count  506.000000  506.000000  506.000000  506.000000\n",
       "mean     0.069170   12.653063    3.613524    6.284634\n",
       "std      0.253994    7.141062    8.601545    0.702617\n",
       "min      0.000000    1.730000    0.006320    3.561000\n",
       "25%      0.000000    6.950000    0.082045    5.885500\n",
       "50%      0.000000   11.360000    0.256510    6.208500\n",
       "75%      0.000000   16.955000    3.677083    6.623500\n",
       "max      1.000000   37.970000   88.976200    8.780000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data[['CHAS', 'LSTAT', 'CRIM','RM']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.92052548]\n",
      " [ 3.9975594 ]\n",
      " [-0.58240212]\n",
      " [-0.09739445]\n",
      " [ 5.07554248]]\n"
     ]
    }
   ],
   "source": [
    "# Рассмотрим модель линейной регрессии по МНК без стандартизации. Помним, что необходимо добавить столбец из единиц:\n",
    "\n",
    "# составляем матрицу наблюдений и вектор целевой переменной\n",
    "A = np.column_stack((np.ones(506), boston_data[['CHAS', 'LSTAT', 'CRIM','RM']]))\n",
    "y = boston_data[['PRICE']]\n",
    "# вычисляем OLS-оценку для коэффициентов без стандартизации\n",
    "w_hat=np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала центрируем векторы, которые находятся в столбцах матрицы . Для этого вычтем среднее, вычисленное по строкам матрицы  в каждом столбце, с помощью метода mean(). Затем разделим результат на длины центрированных векторов, вычисленных с помощью функции linalg.norm().\n",
    "\n",
    "Примечание. Обратите внимание, что для функции linalg.norm() обязательно необходимо указать параметр axis=0, так как по умолчанию норма считается для всей матрицы, а не для каждого столбца в отдельности. С определением нормы матрицы и тем, как она считается, вы можете ознакомиться в документации к функции norm()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.00</td>\n",
       "      <td>506.00</td>\n",
       "      <td>506.00</td>\n",
       "      <td>506.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CHAS   LSTAT    CRIM      RM\n",
       "count  506.00  506.00  506.00  506.00\n",
       "mean    -0.00   -0.00   -0.00   -0.00\n",
       "std      0.04    0.04    0.04    0.04\n",
       "min     -0.01   -0.07   -0.02   -0.17\n",
       "25%     -0.01   -0.04   -0.02   -0.03\n",
       "50%     -0.01   -0.01   -0.02   -0.00\n",
       "75%     -0.01    0.03    0.00    0.02\n",
       "max      0.16    0.16    0.44    0.16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# составляем матрицу наблюдений без дополнительного столбца из единиц\n",
    "A = boston_data[['CHAS', 'LSTAT', 'CRIM','RM']]\n",
    "y = boston_data[['PRICE']]\n",
    "# стандартизируем векторы в столбцах матрицы A\n",
    "A_cent = A - A.mean()\n",
    "A_st = A_cent/np.linalg.norm(A_cent, axis=0)\n",
    "A_st.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Теперь векторы имеют одинаковые средние значения и стандартные отклонения. \n",
    "# Если вычислить длину каждого из векторов, мы увидим, что они будут равны 1:\n",
    "\n",
    "print(np.linalg.norm(A_st, axis=0))\n",
    "## [1. 1. 1. 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для получения стандартизированных коэффициентов нам также понадобится стандартизация целевой переменной  по тому же принципу:\n",
    "\n",
    "# стандартизируем вектор целевой переменной\n",
    "y_cent = y - y.mean()\n",
    "y_st = y_cent/np.linalg.norm(y_cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11039956]\n",
      " [-0.45220423]\n",
      " [-0.09108766]\n",
      " [ 0.38774848]]\n"
     ]
    }
   ],
   "source": [
    "# вычислим OLS-оценку для стандартизированных коэффициентов\n",
    "w_hat_st=np.linalg.inv(A_st.T@A_st)@A_st.T@y_st\n",
    "print(w_hat_st.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.091251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.053929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.613808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.219247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CHAS     LSTAT      CRIM        RM\n",
       "CHAS   1.000000 -0.053929 -0.055892  0.091251\n",
       "LSTAT -0.053929  1.000000  0.455621 -0.613808\n",
       "CRIM  -0.055892  0.455621  1.000000 -0.219247\n",
       "RM     0.091251 -0.613808 -0.219247  1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# матрица Грама\n",
    "A_st.T @ A_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70710678, -0.70710678])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.3\n",
    "# Стандартизируйте вектор \n",
    "x = np.array([12,8]).T\n",
    "# , приведя его к единичной длине. \n",
    "# В качестве ответа введите координаты полученного вектора. Ответ округлите до третьего знака после точки-разделителя.\n",
    "x_cent = x - x.mean()\n",
    "x_std = x_cent/np.linalg.norm(x_cent)\n",
    "x_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# КОРРЕЛЯЦИОННАЯ МАТРИЦА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.18898224],\n",
       "       [-0.18898224,  1.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Примечание. В NumPy матрица корреляций вычисляется функцией np.corrcoef():\n",
    "\n",
    "x_1 = np.array([1, 2, 6])\n",
    "x_2 = np.array([3000, 1000, 2000])\n",
    "np.corrcoef(x_1, x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В Pandas матрица корреляций вычисляется методом corr(), вызванным от имени DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.05241424],\n",
       "       [0.05241424, 1.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.7\n",
    "# Вычислите коэффициент корреляции между векторами  y = 5,1,2 и u = 4,2,8.\n",
    "y = np.array([5,1,2]).T\n",
    "u = np.array([4,2,8]).T\n",
    "np.corrcoef(y,u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 3\n",
      "det= 4.862298229242395e-07\n"
     ]
    }
   ],
   "source": [
    "# 4.8\n",
    "# Составьте корреляционную матрицу для системы векторов:\n",
    "x1 = np.array([5.1, 1.8, 2.1, 10.3, 12.1, 12.6])\n",
    "x2 = np.array([10.2, 3.7, 4.1, 20.5, 24.2, 24.1])\n",
    "x3 = np.array([2.5, 0.9, 1.1, 5.1, 6.1, 6.3])\n",
    "#Для расчёта используйте библиотеку NumPy или Pandas.\n",
    "\n",
    "x = np.array([x1,x2,x3]).T\n",
    "x = pd.DataFrame(x)\n",
    "cor = x.corr()\n",
    "#1. Чему равен ранг полученной корреляционной матрицы?\n",
    "print('rank=', np.linalg.matrix_rank(cor))\n",
    "#2.Чему равен определитель полученной корреляционной матрицы? Ответ округлите до седьмого знака после точки-разделителя.\n",
    "print('det=', np.linalg.det(cor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Практика: линейная регрессия и метод наименьших квадратов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Well</th>\n",
       "      <th>Por</th>\n",
       "      <th>Perm</th>\n",
       "      <th>AI</th>\n",
       "      <th>Brittle</th>\n",
       "      <th>TOC</th>\n",
       "      <th>VR</th>\n",
       "      <th>Prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12.08</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.80</td>\n",
       "      <td>81.40</td>\n",
       "      <td>1.16</td>\n",
       "      <td>2.31</td>\n",
       "      <td>4165.196191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.22</td>\n",
       "      <td>46.17</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3561.146205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14.02</td>\n",
       "      <td>2.59</td>\n",
       "      <td>4.01</td>\n",
       "      <td>72.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.72</td>\n",
       "      <td>4284.348574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17.67</td>\n",
       "      <td>6.75</td>\n",
       "      <td>2.63</td>\n",
       "      <td>39.81</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.88</td>\n",
       "      <td>5098.680869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17.52</td>\n",
       "      <td>4.57</td>\n",
       "      <td>3.18</td>\n",
       "      <td>10.94</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3406.132832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Well    Por  Perm    AI  Brittle   TOC    VR         Prod\n",
       "0     1  12.08  2.92  2.80    81.40  1.16  2.31  4165.196191\n",
       "1     2  12.38  3.53  3.22    46.17  0.89  1.88  3561.146205\n",
       "2     3  14.02  2.59  4.01    72.80  0.89  2.72  4284.348574\n",
       "3     4  17.67  6.75  2.63    39.81  1.08  1.88  5098.680869\n",
       "4     5  17.52  4.57  3.18    10.94  1.51  1.90  3406.132832"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/unconv.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Well       Por      Perm        AI   Brittle       TOC        VR  \\\n",
      "Well     1.000000  0.068927  0.077928  0.041483 -0.079252  0.022624 -0.007279   \n",
      "Por      0.068927  1.000000  0.760546 -0.461549 -0.218570  0.711831  0.111860   \n",
      "Perm     0.077928  0.760546  1.000000 -0.239636 -0.124017  0.471746  0.051023   \n",
      "AI       0.041483 -0.461549 -0.239636  1.000000  0.127599 -0.531864  0.499143   \n",
      "Brittle -0.079252 -0.218570 -0.124017  0.127599  1.000000 -0.214282  0.317929   \n",
      "TOC      0.022624  0.711831  0.471746 -0.531864 -0.214282  1.000000  0.299483   \n",
      "VR      -0.007279  0.111860  0.051023  0.499143  0.317929  0.299483  1.000000   \n",
      "Prod     0.026817  0.861910  0.727426 -0.390835  0.237155  0.654445  0.323182   \n",
      "\n",
      "             Prod  \n",
      "Well     0.026817  \n",
      "Por      0.861910  \n",
      "Perm     0.727426  \n",
      "AI      -0.390835  \n",
      "Brittle  0.237155  \n",
      "TOC      0.654445  \n",
      "VR       0.323182  \n",
      "Prod     1.000000  \n",
      "8\n",
      "0.0007299388072652082\n"
     ]
    }
   ],
   "source": [
    "# 5.1\n",
    "# Постройте корреляционную матрицу факторов, включив в неё целевой признак. Ответьте на следующие вопросы:\n",
    "\n",
    "corr = data.corr()\n",
    "print(corr)\n",
    "print(np.linalg.matrix_rank(corr))\n",
    "print(np.linalg.det(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersept   -1232.0\n",
      "Well            0.0\n",
      "Por           230.0\n",
      "Perm          116.0\n",
      "AI           -365.0\n",
      "Brittle        25.0\n",
      "TOC           -78.0\n",
      "VR            785.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 5.2\n",
    "# Создайте матрицу наблюдений. Обозначьте её за X, а вектор правильных ответов — за y .\n",
    "\n",
    "# 1. Постройте модель линейной регрессии по методу наименьших квадратов. \n",
    "# Для этого используйте матричную формулу NumPy. \n",
    "# В качестве ответа укажите полученные оценки коэффициентов модели. Ответ округлите до целого числа.\n",
    "\n",
    "y = data['Prod']\n",
    "X = data.drop('Prod', axis=1)\n",
    "index = ['intersept'] + list(X.columns)\n",
    "X = np.column_stack((np.ones(200), X))\n",
    "\n",
    "w_hat = np.linalg.inv(X.T@X)@X.T@y\n",
    "print(pd.Series(np.round(w_hat, 0), index=index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-25.25097029]\n",
      "0.03627946845133415\n"
     ]
    }
   ],
   "source": [
    "# 5.3\n",
    "# Далее потренируемся строить предсказание для наблюдений целевой переменной.\n",
    "\n",
    "# 1. Постройте прогноз выработки газа для скважины с параметрами, указанными ниже. \n",
    "# Чему равна абсолютная ошибка построенного вами прогноза для предложенной скважины (в миллионах кубических футов в день).\n",
    "# Ответ округлите до целого числа.\n",
    "\n",
    "new=np.array([[1,106,15.32,3.71,3.29,55.99,1.35,2.42]])\n",
    "y_new = 4748.315024\n",
    "y_pred = (new@w_hat)\n",
    "o = y_pred-y_new\n",
    "\n",
    "print(o)\n",
    "\n",
    "# 2. Постройте прогноз выработки газа для всех скважин из обучающего набора данных. \n",
    "# Чему равно значение метрики MAPE вашей модели? \n",
    "# Ответ приведите в процентах (не указывайте знак процента), округлив его до первого знака после точки-разделителя.\n",
    "\n",
    "from sklearn import metrics\n",
    "pred = X@w_hat\n",
    "print(metrics.mean_absolute_percentage_error(y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.23230803e+03  5.07003631e-02  2.30179140e+02  1.16239006e+02\n",
      " -3.65202301e+02  2.49943700e+01 -7.84009294e+01  7.85259815e+02]\n",
      "             Well       Por      Perm        AI   Brittle       TOC        VR  \\\n",
      "Well     1.000000  0.068927  0.077928  0.041483 -0.079252  0.022624 -0.007279   \n",
      "Por      0.068927  1.000000  0.760546 -0.461549 -0.218570  0.711831  0.111860   \n",
      "Perm     0.077928  0.760546  1.000000 -0.239636 -0.124017  0.471746  0.051023   \n",
      "AI       0.041483 -0.461549 -0.239636  1.000000  0.127599 -0.531864  0.499143   \n",
      "Brittle -0.079252 -0.218570 -0.124017  0.127599  1.000000 -0.214282  0.317929   \n",
      "TOC      0.022624  0.711831  0.471746 -0.531864 -0.214282  1.000000  0.299483   \n",
      "VR      -0.007279  0.111860  0.051023  0.499143  0.317929  0.299483  1.000000   \n",
      "Prod     0.026817  0.861910  0.727426 -0.390835  0.237155  0.654445  0.323182   \n",
      "\n",
      "             Prod  \n",
      "Well     0.026817  \n",
      "Por      0.861910  \n",
      "Perm     0.727426  \n",
      "AI      -0.390835  \n",
      "Brittle  0.237155  \n",
      "TOC      0.654445  \n",
      "VR       0.323182  \n",
      "Prod     1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.4\n",
    "# Настало время анализа построенной модели. \n",
    "# Посмотрите на коэффициенты и сравните их знаки со значениями выборочных корреляций между целевым признаком и факторами, \n",
    "# которые вы нашли ранее.\n",
    "\n",
    "# 1. Есть ли в вашей модели фактор, при котором коэффициент в модели линейной регрессии противоречит соответствующему коэффициенту корреляции? \n",
    "# Например, корреляция говорит, что зависимость между фактором и целью прямая, а модель говорит обратное.\n",
    "\n",
    "# Если такой фактор есть, выберите его название из списка. Если таких факторов несколько, выберите их все:\n",
    "\n",
    "print(w_hat)\n",
    "print(corr)\n",
    "sns.heatmap(corr,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersept   -1835.0\n",
      "Por           293.0\n",
      "AI           -200.0\n",
      "Brittle        28.0\n",
      "VR            517.0\n",
      "dtype: float64\n",
      "0.04044138420436065\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.5\n",
    "# 1. Исключите из данных сильно коррелированные между собой факторы. \n",
    "# Под сильной корреляцией в данной задаче будем понимать значения, выше 0.7. \n",
    "# Выбирая, какой из коррелированных факторов оставить, руководствуйтесь коэффициентом корреляции с целевой переменной: \n",
    "# оставляйте тот фактор, который больше всего коррелирует с объёмом добычи газа.\n",
    "\n",
    "# Также исключите из данных факторы, для которых корреляция с целевой переменной меньше 0.05.\n",
    "\n",
    "delete = ['Perm', 'TOC', 'Well']\n",
    "new_data = data.drop(delete,axis=1)\n",
    "\n",
    "sns.heatmap(new_data.corr(), annot = True)\n",
    "\n",
    "# 2. Постройте линейную регрессию на обновлённых после удаления факторов данных по методу наименьших квадратов. \n",
    "# Для этого используйте матричную формулу NumPy.\n",
    "\n",
    "# В качестве ответа укажите полученные оценки коэффициентов модели. Ответ округлите до целого числа.\n",
    "y = new_data['Prod']\n",
    "X = new_data.drop('Prod', axis=1)\n",
    "index = ['intersept'] + list(X.columns)\n",
    "X = np.column_stack((np.ones(200), X))\n",
    "\n",
    "w_hat = np.linalg.inv(X.T@X)@X.T@y\n",
    "print(pd.Series(np.round(w_hat, 0), index=index))\n",
    "\n",
    "# 3. Сделайте прогноз для всего обучающего набора данных и рассчитайте метрику MAPE (Mean Absolute Percentage Error). \n",
    "# Результат приведите в процентах (не указывайте знак процента), округлив его до первого знака после точки-разделителя.\n",
    "\n",
    "pred = X@w_hat\n",
    "print(metrics.mean_absolute_percentage_error(y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Полиномиальная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4        0.46666667 0.13333333]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 3, -2, 1],\n",
    "    [1, 9, 4, 1]\n",
    "]).T\n",
    "y = np.array([4, 5, 2, 2])\n",
    "w_hat = np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat) \n",
    "# [2.4        0.46666667 0.13333333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.25799015  2.37672337 -0.1322068  -0.10208147 -0.26501791  0.29722471]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 3, -2, 1, 5, 13, 1],\n",
    "    [3, 4, 5, -2, 4, 11, 3],\n",
    "    [1, 9, 4, 1, 25, 169, 1],\n",
    "    [3, 12, -10, -2, 20, 143, 3],\n",
    "    [9, 16, 25, 4, 16, 121, 9]\n",
    "    \n",
    "]).T\n",
    "y = np.array([4, 5, 2, 2, 6, 8, -1])\n",
    "w_hat = np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat)\n",
    "## [-2.25799015  2.37672337 -0.1322068  -0.10208147 -0.26501791  0.29722471]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно, вручную создавать полиномиальные столбцы в матрице наблюдений мы не будем. В модуле «ML-2. Обучение с учителем: регрессия» мы с вами уже знакомились с полиномиальными признаками, генерация которых реализована в классе PolynomialFeatures из модуля preprocessing. \n",
    "\n",
    "Потренируемся на следующем примере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  4]\n",
      " [ 3  4  5]\n",
      " [-2  5  2]\n",
      " [ 1 -2  2]\n",
      " [ 5  4  6]\n",
      " [13 11  8]\n",
      " [ 1  3 -1]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 3, -2, 1, 5, 13, 1],\n",
    "    [3, 4, 5, -2, 4, 11, 3],\n",
    "    [4, 5, 2, 2, 6, 8, -1],\n",
    "]).T\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Затем импортируем класс PolynomialFeatures из библиотеки sklearn. \n",
    "# Создадим объект этого класса, указав при инициализации степень полинома равной 2. \n",
    "# Также укажем, что нам нужна генерация столбца из 1 (параметр include_bias=True):\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2, include_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4      5      6      7     8     9\n",
       "0  1.0   1.0   3.0  4.0    1.0    3.0    4.0    9.0  12.0  16.0\n",
       "1  1.0   3.0   4.0  5.0    9.0   12.0   15.0   16.0  20.0  25.0\n",
       "2  1.0  -2.0   5.0  2.0    4.0  -10.0   -4.0   25.0  10.0   4.0\n",
       "3  1.0   1.0  -2.0  2.0    1.0   -2.0    2.0    4.0  -4.0   4.0\n",
       "4  1.0   5.0   4.0  6.0   25.0   20.0   30.0   16.0  24.0  36.0\n",
       "5  1.0  13.0  11.0  8.0  169.0  143.0  104.0  121.0  88.0  64.0\n",
       "6  1.0   1.0   3.0 -1.0    1.0    3.0   -1.0    9.0  -3.0   1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_poly = poly.fit_transform(A)\n",
    "display(pd.DataFrame(A_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь построим модель полиномиальной регрессии на реальных данных.\n",
    "\n",
    "Возьмём все те же данные о стоимости жилья в районах Бостона. Будем использовать следующие четыре признака: LSTAT, CRIM, PTRATIO и RM. С их помощью мы построим полиномиальную регрессию от первой до пятой степени включительно, а затем сравним результаты по значению средней абсолютной процентной ошибки (MAPE).\n",
    "\n",
    "Чтобы не дублировать код, объявим функцию polynomial_regression(). Она будет принимать на вход матрицу наблюдений, вектор ответов и степень полинома, а возвращать матрицу с полиномиальными признаками, вектор предсказаний и коэффициенты регрессии, найденные по МНК:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression(X, y, k):\n",
    "    poly = PolynomialFeatures(degree=k, include_bias=True)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    w_hat = np.linalg.inv(X_poly.T@X_poly)@X_poly.T@y\n",
    "    y_pred = X_poly @ w_hat\n",
    "    return X_poly, y_pred, w_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = boston_data[['LSTAT', 'PTRATIO', 'RM', 'CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    " \n",
    "A_poly, y_pred, w_hat = polynomial_regression(A, y, 1)\n",
    "A_poly2, y_pred2, w_hat2 = polynomial_regression(A, y, 2)\n",
    "A_poly3, y_pred3, w_hat3 = polynomial_regression(A, y, 3)\n",
    "A_poly4, y_pred4, w_hat4 = polynomial_regression(A, y, 4)\n",
    "A_poly5, y_pred5, w_hat5 = polynomial_regression(A, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE для полинома 1-й степени 18.20%\n",
      "MAPE для полинома 2-й степени  13.41%\n",
      "MAPE для полинома 3-й степени  12.93%\n",
      "MAPE для полинома 4-й степени  10.73%\n",
      "MAPE для полинома 5-й степени  1092.80%\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на качество построенных регрессий, вычислив метрику:\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    " \n",
    "print('MAPE для полинома 1-й степени {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred)*100))\n",
    "print('MAPE для полинома 2-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred2)*100))\n",
    "print('MAPE для полинома 3-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred3)*100))\n",
    "print('MAPE для полинома 4-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred4)*100))\n",
    "print('MAPE для полинома 5-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred5)*100))\n",
    "## MAPE для полинома 1-й степени 18.20%\n",
    "## MAPE для полинома 2-й степени  13.41%\n",
    "## MAPE для полинома 3-й степени  12.93%\n",
    "## MAPE для полинома 4-й степени  10.74%\n",
    "## MAPE для полинома 5-й степени  5328.16%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1133.563801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30817.017070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-144241.899739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.684799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.530654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>308300.929269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PRICE\n",
       "count     126.000000\n",
       "mean     1133.563801\n",
       "std     30817.017070\n",
       "min   -144241.899739\n",
       "25%        -0.684799\n",
       "50%        -0.000308\n",
       "75%         1.530654\n",
       "max    308300.929269"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(w_hat5).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранг корреляционной матрицы: 110\n",
      "Количество факторов: 125\n"
     ]
    }
   ],
   "source": [
    "# считаем матрицу корреляций (без столбца из единиц)\n",
    "C = pd.DataFrame(A_poly5[:, 1:]).corr()\n",
    "# считаем ранг корреляционной матрицы\n",
    "print('Ранг корреляционной матрицы:', np.linalg.matrix_rank(C))\n",
    "# считаем количество факторов (не включая столбец из единиц)\n",
    "print('Количество факторов:', A_poly5[:, 1:].shape[1])\n",
    "# Ранг корреляционной матрицы: 110\n",
    "# Количество факторов: 125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кстати, заметим, что, например, для полинома четвёртой степени ранг матрицы корреляций максимален, то есть равен количеству факторов (не включая единичный столбец):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранг корреляционной матрицы: 69\n",
      "Количество факторов: 69\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# считаем матрицу корреляций (без столбца из единиц)\n",
    "C = pd.DataFrame(A_poly4[:, 1:]).corr()\n",
    "# считаем ранг корреляционной матрицы\n",
    "print('Ранг корреляционной матрицы:', np.linalg.matrix_rank(C))\n",
    "# считаем количество факторов (не включая столбец из единиц)\n",
    "print('Количество факторов:', A_poly4[:, 1:].shape[1])\n",
    "## Ранг корреляционной матрицы: 69\n",
    "## Количество факторов: 69\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-50.785591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>886.319182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6916.525964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.187934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.322186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2304.602371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PRICE\n",
       "count    70.000000\n",
       "mean    -50.785591\n",
       "std     886.319182\n",
       "min   -6916.525964\n",
       "25%      -0.187934\n",
       "50%      -0.000810\n",
       "75%       0.322186\n",
       "max    2304.602371"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(w_hat4).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь посмотрим, что будет, если использовать для построения полиномиальной регрессии реализацию из библиотеки sklearn. Создадим функцию polynomial_regression_sk — она будет делать то же самое, что и прошлая функция, но средствами sklearn. Дополнительно будем смотреть также стандартное отклонение (разброс) по коэффициентам регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE для полинома степени 1 — 18.20%, СКО — 2\n",
      "MAPE для полинома степени 2 — 13.41%, СКО — 5\n",
      "MAPE для полинома степени 3 — 12.93%, СКО — 9\n",
      "MAPE для полинома степени 4 — 10.74%, СКО — 304\n",
      "MAPE для полинома степени 5 — 9.02%, СКО — 17055\n"
     ]
    }
   ],
   "source": [
    "def polynomial_regression_sk(X, y, k):\n",
    "    poly = PolynomialFeatures(degree=k, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    lr = LinearRegression().fit(X_poly, y)\n",
    "    y_pred = lr.predict(X_poly)\n",
    "    return X_poly, y_pred, lr.coef_\n",
    "\n",
    "A = boston_data[['LSTAT', 'PTRATIO', 'RM', 'CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "\n",
    "for k in range(1, 6):\n",
    "    A_poly, y_pred, w_hat = polynomial_regression_sk(A, y, k)\n",
    "    print(\n",
    "        \"MAPE для полинома степени {} — {:.2f}%, СКО — {:.0f}\".format(\n",
    "            k, mean_absolute_percentage_error(y, y_pred)*100, w_hat.std()\n",
    "        )\n",
    "\n",
    "    )\n",
    "## MAPE для полинома степени 1 — 0.68, СКО — 2\n",
    "## MAPE для полинома степени 2 — 0.81, СКО — 5\n",
    "## MAPE для полинома степени 3 — 0.86, СКО — 9\n",
    "## MAPE для полинома степени 4 — 0.91, СКО — 304\n",
    "## MAPE для полинома степени 5 — 0.93, СКО — 17055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.799999999999997"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.1\n",
    "# Построена модель полиномиальной регрессии следующего вида:\n",
    "# Поступило новое наблюдение, которое характеризуется вектором .\n",
    "\n",
    "# Сделайте прогноз целевой переменной с помощью полученной полиномиальной регрессии. \n",
    "# Ответ округлите до первого знака после точки-разделителя\n",
    "\n",
    "y_pred = 10.4 +8 + 0.5*4 + 3+ 0.4*4*4\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1     2\n",
       "0  1.0  1.0   1.0\n",
       "1  1.0  3.0   9.0\n",
       "2  1.0 -2.0   4.0\n",
       "3  1.0  9.0  81.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6.2\n",
    "# Строится полиномиальная регрессия второй степени от одного фактора . Как будет выглядеть матрица наблюдений , если: x = 1,3,-2,9 \n",
    "X = np.array([1,3,-2,9]).T \n",
    "X = X.reshape(4,1)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=True)\n",
    "X_poly = poly.fit_transform(X)\n",
    "display(pd.DataFrame(X_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11446013],\n",
       "       [ 2.46095638],\n",
       "       [-0.01608801]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.5\n",
    "# С помощью классического МНК найдите коэффициенты полиномиальной регрессии, \n",
    "# если используется полином второй степени и задан фактор  и целевая переменная\n",
    "\n",
    "x = np.array([1,3,-2,9])\n",
    "y = np.array([3,7,-5,21])\n",
    "x = x.reshape(4,1)\n",
    "y = y.reshape(4,1)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=True)\n",
    "X_poly = poly.fit_transform(x)\n",
    "w_hat = np.linalg.inv(X_poly.T@X_poly)@X_poly.T@y\n",
    "w_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель полиномиальной регрессии третьей степени. Будем использовать данные о жилье в Бостоне и возьмём следующие четыре признака: LSTAT, CRIM, PTRATIO и RM.\n",
    "\n",
    "Для оценки качества модели будем использовать кросс-валидацию и сравнивать среднее значение метрики на тренировочных и валидационных фолдах. Кросс-валидацию организуем с помощью функции cross_validate из модуля model_selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.64 %\n",
      "MAPE на валидационных фолдах: 24.16 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    " \n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    " \n",
    "# создаём модель линейной регрессии\n",
    "lr = LinearRegression()\n",
    " \n",
    "# оцениваем качество модели на кросс-валидации, метрика — MAPE\n",
    "cv_results = cross_validate(lr, X, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))\t\n",
    " \n",
    "## MAPE на тренировочных фолдах: 12.64 %\n",
    "## MAPE на валидационных фолдах: 24.16 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/kseniamasnikova/IDE/SkillFactory/MATH/MATH_2/MATH_2.ipynb Cell 67'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kseniamasnikova/IDE/SkillFactory/MATH/MATH_2/MATH_2.ipynb#ch0000074?line=10'>11</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m4\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m4\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m7\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kseniamasnikova/IDE/SkillFactory/MATH/MATH_2/MATH_2.ipynb#ch0000074?line=11'>12</a>\u001b[0m \u001b[39m# получаем оценку коэффициентов регрессии по МНК\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kseniamasnikova/IDE/SkillFactory/MATH/MATH_2/MATH_2.ipynb#ch0000074?line=12'>13</a>\u001b[0m w_hat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(A\u001b[39m.\u001b[39;49mT\u001b[39m@A\u001b[39;49m)\u001b[39m@A\u001b[39m\u001b[39m.\u001b[39mT\u001b[39m@y\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kseniamasnikova/IDE/SkillFactory/MATH/MATH_2/MATH_2.ipynb#ch0000074?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(w_hat)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py:545\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py?line=542'>543</a>\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py?line=543'>544</a>\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py?line=544'>545</a>\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py?line=545'>546</a>\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py:88\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py?line=86'>87</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m---> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py?line=87'>88</a>\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# Здесь Очевидно, что матрица  вырождена: её второй и третий столбцы являются пропорциональными с коэффициентом 2. \n",
    "# Значит, наша классическая формула МНК  (без сингулярного разложения) не сработает.\n",
    "\n",
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# получаем оценку коэффициентов регрессии по МНК\n",
    "w_hat = np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat) \n",
    "## LinAlgError: Singular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6122449  0.29387755 0.5877551 ]\n"
     ]
    }
   ],
   "source": [
    "# Попробуем найти вектор оценок весов  по формуле:\n",
    "\n",
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# единичная матрица\n",
    "E = np.eye(3)\n",
    "# коэффициент регуляризации \n",
    "alpha = 5\n",
    "# получаем оценку коэффициентов регрессии по МНК с регуляризацией Тихонова\n",
    "w_hat_ridge = np.linalg.inv(A.T@A+alpha*E)@A.T@y\n",
    "print(w_hat_ridge) \n",
    "## [0.6122449  0.29387755 0.5877551 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2-РЕГУЛЯРИЗАЦИЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомним, что за реализацию линейной регрессии в sklearn отвечает класс Ridge. Основной параметр модели, на который стоит обратить внимание — alpha, коэффициент регуляризации из формулы Тихонова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6122449  0.29387755 0.5877551 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# получаем оценку коэффициентов регрессии по МНК с регуляризацией Тихонова\n",
    "ridge = Ridge(alpha=5, fit_intercept=False)\n",
    "ridge.fit(A, y)\n",
    "print(ridge.coef_) \n",
    "## [0.6122449  0.29387755 0.5877551 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, посмотрим, как регуляризация поможет побороть переобучение модели полиномиальной регрессии на наборе данных о домах в Бостоне. Используем те же самые признаки: LSTAT, CRIM, PTRATIO и RM. \n",
    "\n",
    "→ Сразу отметим, что для успешной сходимости численных методов оптимизации, которые используются для решения задачи условной оптимизации, необходима стандартизация (нормализация) исходных данных, которая не требовалась для аналитического МНК в классической линейной регрессии (LinearRegression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.54 %\n",
      "MAPE на валидационных фолдах: 17.02 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "# создаём модель линейной регрессии c L2-регуляризацией\n",
    "ridge = Ridge(alpha=20, solver='svd')\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(ridge, X, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))\n",
    "## MAPE на тренировочных фолдах: 12.54 %\n",
    "## MAPE на валидационных фолдах: 17.02 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08523045 -1.70784126  1.91141216  0.7293992 ]\n"
     ]
    }
   ],
   "source": [
    "# 7.4\n",
    "# Вычислите коэффициенты линейной регрессии с -регуляризацией, используя аналитическую формулу Тихонова, если:\n",
    "# коэффициент = 1\n",
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1,1,1,1,1],\n",
    "    [5,9,4,3,5],\n",
    "    [15,18,18,19,19],\n",
    "    [7,6,7,7,7]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([24,22,35,33,36])\n",
    "# получаем оценку коэффициентов регрессии по МНК с регуляризацией Тихонова\n",
    "ridge = Ridge(alpha=1, fit_intercept=False)\n",
    "ridge.fit(A, y)\n",
    "print(ridge.coef_) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1-РЕГУЛЯРИЗАЦИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14925373 0.         0.71921642]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# получаем оценку коэффициентов регрессии с помощью L1-регуляризации\n",
    "lasso = Lasso(alpha=0.1, fit_intercept=False)\n",
    "lasso.fit(A, y)\n",
    "print(lasso.coef_)\n",
    "## [1.14925373 0.         0.71921642]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.44 %\n",
      "MAPE на валидационных фолдах: 16.44 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "# создаём модель линейной регрессии c L1-регуляризацией\n",
    "lasso = Lasso(alpha=0.1, max_iter=10000)\n",
    "\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(lasso, X, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))\n",
    "## MAPE на тренировочных фолдах: 12.44 %\n",
    "## MAPE на валидационных фолдах: 16.44 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELASTIC-NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn эластичная сетка реализована в классе ElasticNet из пакета с линейными моделями — linear_model. За коэффициент  отвечает параметр alpha, за коэффициент  — l1_ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.13492457 0.19525842 0.6237965 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# получаем оценку коэффициентов регрессии \n",
    "lasso = ElasticNet(alpha=0.1, l1_ratio=0.2, fit_intercept=False)\n",
    "lasso.fit(A, y)\n",
    "print(lasso.coef_)\n",
    "## [1.13492457 0.19525842 0.6237965 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.65 %\n",
      "MAPE на валидационных фолдах: 15.70 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "# создаём модель линейной регрессии c L1- и L2-регуляризациями\n",
    "lasso = ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000)\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(lasso, X, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100)) \n",
    "## MAPE на тренировочных фолдах: 12.65 %\n",
    "## MAPE на валидационных фолдах: 15.70 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Практика: полиномиальная регрессия и регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные из юнита 5 (прогнать тот код)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 34)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 1.77 %\n",
      "MAPE на валидационных фолдах: 2.68 %\n"
     ]
    }
   ],
   "source": [
    "# 8.1 \n",
    "# Сгенерируйте полиномиальные признаки третьего порядка на факторах, которые вы выбрали для обучения моделей. \n",
    "# Для этого воспользуйтесь генератором полиномов PolynomialFeatures из библиотеки sklearn. \n",
    "# Параметр include_bias установите в значение False.\n",
    "\n",
    "# 1. Сколько факторов у вас получилось после генерации полиномиальных признаков?\n",
    "\n",
    "y = new_data['Prod']\n",
    "X = new_data.drop('Prod', axis=1)\n",
    "# index = ['intersept'] + list(X.columns)\n",
    "# X = np.column_stack((np.ones(200), X))\n",
    "\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "display(X_poly.shape)\n",
    "\n",
    "# Обучите модель линейной регрессии из библиотеки sklearn (LinearRegression) на полученных полиномиальных факторах.\n",
    "# Оцените среднее значение метрики MAPE, используя кросс-валидацию на пяти фолдах.\n",
    "\n",
    "# 2. Чему равны средние значения метрики MAPE на тренировочных и валидационных фолдах? \n",
    "# Ответ приведите в процентах (не указывайте знак процента), округлив его до первого знака после точки-разделителя.\n",
    "\n",
    "# w_hat = np.linalg.inv(X_poly.T@X_poly)@X_poly.T@y\n",
    "# y_pred = X_poly @ w_hat\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "cv_results = cross_validate(lr, X_poly, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100)) \n",
    "\n",
    "# w_hat = np.linalg.inv(X.T@X)@X.T@y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 1.83 %\n",
      "MAPE на валидационных фолдах: 2.28 %\n"
     ]
    }
   ],
   "source": [
    "# 8.2\n",
    "# Теперь попробуем воспользоваться линейной регрессией с регуляризацией. Для начала возьмём L1-регуляризацию.\n",
    "\n",
    "# Обучите модель Lasso из библиотеки sklearn на полученных полиномиальных факторах, \n",
    "# предварительно стандартизировав факторы с помощью StandardScaler. Коэффициент регуляризации выставите равным 5.\n",
    "\n",
    "# Оцените среднее значение метрики MAPE, используя кросс-валидацию на пяти фолдах.\n",
    "\n",
    "# Чему равны средние значения метрики MAPE на тренировочных и валидационных фолдах? \n",
    "# Ответ приведите в процентах (не указывайте знак процента), округлив его до первого знака после точки-разделителя.\n",
    "\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# создаём модель линейной регрессии c L1-регуляризацией\n",
    "lasso = Lasso(alpha=5, max_iter=10000)\n",
    "\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(lasso, X_poly, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 1.83 %\n",
      "MAPE на валидационных фолдах: 2.72 %\n"
     ]
    }
   ],
   "source": [
    "# 8.3\n",
    "\n",
    "# Проделаем то же самое с -регуляризацией.\n",
    "# Обучите модель Ridge из библиотеки sklearn на полученных полиномиальных факторах, \n",
    "# предварительно стандартизировав факторы с помощью StandardScaler. Коэффициент регуляризации выставите равным 1.\n",
    "# Оцените среднее значение метрики MAPE, используя кросс-валидацию на пяти фолдах.\n",
    "\n",
    "# Чему равны средние значения метрики MAPE на тренировочных и валидационных фолдах? \n",
    "# Ответ приведите в процентах (не указывайте знак процента), округлив его до первого знака после точки-разделителя.\n",
    "\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "# создаём модель линейной регрессии c L2-регуляризацией\n",
    "ridge = Ridge(alpha=1, solver='svd')\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(ridge, X_poly, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))\n",
    "## MAPE на тренировочных фолдах: 12.54 %\n",
    "## MAPE на валидационных фолдах: 17.02 %"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
